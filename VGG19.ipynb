{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e25ca5ed-053d-4ef7-8e1c-c0f7f9c3973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e43ac300-9b4a-450a-bf95-2c70af506683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into training and testing sets.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define paths\n",
    "original_dataset_dir = '/Users/code/alzheimerDetect/OriginalDataset'\n",
    "base_dir = '/Users/code/alzheimerDetect/split_dataset'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Create directories for training and testing data\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Define categories\n",
    "categories = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "\n",
    "for category in categories:\n",
    "    os.makedirs(os.path.join(train_dir, category), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, category), exist_ok=True)\n",
    "\n",
    "    # List files in the category directory\n",
    "    category_dir = os.path.join(original_dataset_dir, category)\n",
    "    files = os.listdir(category_dir)\n",
    "    \n",
    "    # Split the data\n",
    "    train_files, test_files = train_test_split(files, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Copy files to train directory\n",
    "    for file in train_files:\n",
    "        src = os.path.join(category_dir, file)\n",
    "        dst = os.path.join(train_dir, category, file)\n",
    "        shutil.copyfile(src, dst)\n",
    "    \n",
    "    # Copy files to test directory\n",
    "    for file in test_files:\n",
    "        src = os.path.join(category_dir, file)\n",
    "        dst = os.path.join(test_dir, category, file)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "print(\"Dataset split into training and testing sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d3cad37-df67-4c8e-8f5b-7e29bb5db24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1/255.0,\n",
    "    validation_split=0.2  # 20% of the data will be used for validation\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1/255.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "374c8294-f170-4e8c-8ab8-1be1cdf90ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4096 images belonging to 4 classes.\n",
      "Found 1023 images belonging to 4 classes.\n",
      "Found 1281 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training data and validation data from the training directory\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),  # Resize images to 150x150 pixels\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Adjusted for multi-class classification\n",
    "    subset='training'  # Set as training data\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Adjusted for multi-class classification\n",
    "    subset='validation'  # Set as validation data\n",
    ")\n",
    "\n",
    "# Load test data from the test directory\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'  # Adjusted for multi-class classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ef54a0-7092-4c96-8543-0c02db677d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 17:39:19.015284: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-09-22 17:39:19.015334: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-09-22 17:39:19.015362: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-09-22 17:39:19.015596: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-22 17:39:19.015621: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Load the VGG19 model with pretrained ImageNet weights, without the top classification layer\n",
    "vgg = VGG19(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "# Freeze all the layers in VGG19 so their weights don't get updated during training\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers to the base VGG19 model\n",
    "x = Flatten()(vgg.output)  # Flatten the output from VGG19\n",
    "x = Dense(512, activation='relu')(x)  # Add a fully connected layer with 512 units\n",
    "x = Dropout(0.5)(x)  # Add dropout to reduce overfitting\n",
    "output = Dense(4, activation='softmax')(x)  # Final output layer for multi-class classification\n",
    "\n",
    "# Create the full model by combining VGG19 base with the custom layers\n",
    "model = Model(inputs=vgg.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4f9e1d5-81b6-4a21-bdc0-59aa371ad2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an EarlyStopping callback\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d29944c2-1ecb-4512-95dc-9a1f3f2d461f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 17:39:56.688028: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "/opt/anaconda3/envs/tf_env/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 249ms/step - accuracy: 0.4736 - loss: 1.6133 - val_accuracy: 0.5181 - val_loss: 0.9536\n",
      "Epoch 2/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 245ms/step - accuracy: 0.5400 - loss: 0.9578 - val_accuracy: 0.5533 - val_loss: 0.9115\n",
      "Epoch 3/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 246ms/step - accuracy: 0.5517 - loss: 0.9194 - val_accuracy: 0.5728 - val_loss: 0.8876\n",
      "Epoch 4/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 248ms/step - accuracy: 0.5931 - loss: 0.8580 - val_accuracy: 0.5718 - val_loss: 0.9227\n",
      "Epoch 5/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 250ms/step - accuracy: 0.5824 - loss: 0.8781 - val_accuracy: 0.5885 - val_loss: 0.8610\n",
      "Epoch 6/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 251ms/step - accuracy: 0.6193 - loss: 0.8441 - val_accuracy: 0.6041 - val_loss: 0.8604\n",
      "Epoch 7/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 250ms/step - accuracy: 0.5963 - loss: 0.8299 - val_accuracy: 0.6158 - val_loss: 0.8298\n",
      "Epoch 8/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 247ms/step - accuracy: 0.6197 - loss: 0.8068 - val_accuracy: 0.5934 - val_loss: 0.9103\n",
      "Epoch 9/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 271ms/step - accuracy: 0.6412 - loss: 0.7897 - val_accuracy: 0.6510 - val_loss: 0.8016\n",
      "Epoch 10/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 288ms/step - accuracy: 0.6345 - loss: 0.7831 - val_accuracy: 0.6676 - val_loss: 0.8069\n",
      "Epoch 11/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 291ms/step - accuracy: 0.6263 - loss: 0.7891 - val_accuracy: 0.5806 - val_loss: 0.8677\n",
      "Epoch 12/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 281ms/step - accuracy: 0.6297 - loss: 0.7761 - val_accuracy: 0.6500 - val_loss: 0.7835\n",
      "Epoch 13/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 257ms/step - accuracy: 0.6558 - loss: 0.7298 - val_accuracy: 0.6745 - val_loss: 0.7926\n",
      "Epoch 14/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 256ms/step - accuracy: 0.6857 - loss: 0.6994 - val_accuracy: 0.6579 - val_loss: 0.8694\n",
      "Epoch 15/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 251ms/step - accuracy: 0.6349 - loss: 0.7309 - val_accuracy: 0.6755 - val_loss: 0.7931\n",
      "Epoch 16/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 249ms/step - accuracy: 0.6509 - loss: 0.7456 - val_accuracy: 0.6569 - val_loss: 0.7900\n",
      "Epoch 17/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 247ms/step - accuracy: 0.6669 - loss: 0.7050 - val_accuracy: 0.6833 - val_loss: 0.7848\n",
      "Epoch 18/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 248ms/step - accuracy: 0.6496 - loss: 0.7122 - val_accuracy: 0.6745 - val_loss: 0.8376\n",
      "Epoch 19/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 253ms/step - accuracy: 0.6672 - loss: 0.6973 - val_accuracy: 0.6725 - val_loss: 0.8044\n",
      "Epoch 20/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 248ms/step - accuracy: 0.6735 - loss: 0.6806 - val_accuracy: 0.6833 - val_loss: 0.7638\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c6de255-8e75-48d0-ac29-256291af12fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - accuracy: 0.7360 - loss: 0.6226\n",
      "Test accuracy: 0.7229\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f'Test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9024db07-6238-482a-9d44-e3d8eff5bc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "model.save('alzheimers_detector_model_with_originalDS_cnn_VGG_arch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699b2eed-94c2-4068-a764-e8340be1d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, plot the training and validation accuracy and loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e4526a-7cbd-4ef5-a7bb-94bcde4638bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the path to the image\n",
    "image_path = 'split_dataset/test/MildDemented/29 (4).jpg'\n",
    "\n",
    "# Load the image\n",
    "img = image.load_img(image_path, target_size=(150, 150))\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.title(\"MRI Scan\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Preprocess the image\n",
    "img_array = image.img_to_array(img)  # Convert the image to a numpy array\n",
    "img_array = img_array / 255.0  # Rescale the image\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to match the model's input shape\n",
    "\n",
    "# Make a prediction\n",
    "prediction = model.predict(img_array)\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = class_labels[np.argmax(prediction[0])]\n",
    "\n",
    "print(f'The model predicts: {predicted_class} ({prediction[0][np.argmax(prediction[0])]:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa0f622-fd4b-48a7-94fc-4a482cb41888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('alzheimers_detector_model_with_originalDS_cnn_VGG_arch.h5')\n",
    "\n",
    "# Define the path to the image\n",
    "image_path = '/Users/arnabsahoo/Downloads/FinalPriject/Alzheimer_s Dataset/test/VeryMildDemented/26 (53).jpg'\n",
    "\n",
    "# Load the image\n",
    "img = image.load_img(image_path, target_size=(150, 150))\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.title(\"MRI Scan\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Preprocess the image\n",
    "img_array = image.img_to_array(img)  # Convert the image to a numpy array\n",
    "img_array = img_array / 255.0  # Rescale the image\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to match the model's input shape\n",
    "\n",
    "# Make a prediction\n",
    "prediction = model.predict(img_array)\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = class_labels[np.argmax(prediction[0])]\n",
    "\n",
    "print(f'The model predicts: {predicted_class} ({prediction[0][np.argmax(prediction[0])]:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52632771-d9a4-476a-be64-34dc86f782fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting accuracy and loss for each batch\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(accuracy_per_batch, label='Test Accuracy')\n",
    "plt.title('Model Accuracy per Batch')\n",
    "plt.xlabel('Batch Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss_per_batch, label='Test Loss', color='red')\n",
    "plt.title('Model Loss per Batch')\n",
    "plt.xlabel('Batch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
